{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMreyIy8Rm36xmN2hHIX4Nh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# TensorFlow Datasets\n","In this assignment you will create a data pipeline with for a cool Rock Paper Scissors model"],"metadata":{"id":"KRt0XWYN379z"}},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_datasets as tfds"],"metadata":{"id":"oJ56MwEm4Ye0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1. Loading Dataset\n","load the Rock Paper Scissors Dataset from TFDS:\n","https://www.tensorflow.org/datasets/catalog/rock_paper_scissors \\\n","This Dataset have two splits: Train, Test\\\n","In here we want three splits: Train, Validation and Test. So we should use TFDS split method to keep 80% of original Train split for training set, remaining 20% for validation set and all of the original Test split for test set:"],"metadata":{"id":"_2lwHbSY4O29"}},{"cell_type":"code","source":["(train_ds, val_ds, test_ds), metadata = # Code Here"],"metadata":{"id":"_twAg52B4ObY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Inspecting Dataset"],"metadata":{"id":"2p7Np9995wzy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y1hgDFJX3Ove"},"outputs":[],"source":["num_classes = metadata.features['label'].num_classes\n","get_label_name = metadata.features['label'].int2str\n","print(f\"Number of classes in the dataset: {num_classes}\")\n","for i in range(num_classes):\n","    print(f\"class id {i} is {get_label_name(i)}\")"]},{"cell_type":"markdown","source":["As you see we have three classes for this dataset.\n","Now use `tfds.visualization.show_example` function to viusalize some data from training dataset.\\\n","https://www.tensorflow.org/datasets/api_docs/python/tfds/visualization/show_examples"],"metadata":{"id":"ClgZN9H36nsB"}},{"cell_type":"code","source":["# Code Here"],"metadata":{"id":"gRkkvA0V6naX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Preprocessing\n","Now write a python function that resize images to `224x224` and rescale the pixels to be between  `[0,1]` (You can use [tf.image](https://www.tensorflow.org/api_docs/python/tf/image/resize) and [tf.divide](https://https://www.tensorflow.org/api_docs/python/tf/math/divide))"],"metadata":{"id":"Y_nRTVFN7rfv"}},{"cell_type":"code","source":["def preprocess(image, label):\n","    #Code Here\n","    return image, encoded_label"],"metadata":{"id":"s-kcF-If5906"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now by using `map` method apply this preprocessing function to all splits: (use `num_parallel_calls` argument in map function to run the function faster)"],"metadata":{"id":"CBzFY0qw9QnR"}},{"cell_type":"code","source":["AUTOTUNE = tf.data.AUTOTUNE\n","train_ds = #Code Here\n","val_ds = #Code Here\n","test_ds = #Code Here"],"metadata":{"id":"cHrewtfb9OdF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Data Augmentation\n","Create a sequential model with three augmentation layer:\n","1. [Random Flip](https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_flip/)\n","2. [Random Rotation](https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_rotation/)\n","3. [Random Zoom](https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_zoom/)"],"metadata":{"id":"az_lE5rU-pNu"}},{"cell_type":"code","source":["data_augmentation = #Code Here"],"metadata":{"id":"rSd78hnQ9-CO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Use `map` method to apply these augmentation layers to the training data set. (use `num_parallel_calls` argument in map function to run the function faster)"],"metadata":{"id":"6LPlIiSiABLV"}},{"cell_type":"code","source":["train_ds = #Code Here"],"metadata":{"id":"jjglJTfz__Sp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Shuffle and Batch"],"metadata":{"id":"0ISBB3HJBizI"}},{"cell_type":"markdown","source":["Shuffle training data and batch all splits"],"metadata":{"id":"bQIadQrFBmqp"}},{"cell_type":"code","source":["batch_size = 16\n","buffer_size = 1000\n","train_ds = #Code Here\n","train_ds = #Code Here\n","val_ds = #Code Here\n","test_ds = #Code Here"],"metadata":{"id":"9k7jY0u0AfsL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Add cache and prefetch for optimizing the pipeline:"],"metadata":{"id":"9Gt5ODvgKQtg"}},{"cell_type":"code","source":["train_ds = #Code Here\n","val_ds = #Code Here\n","test_ds = #Code Here"],"metadata":{"id":"_xB02Wb9KMxk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6. Model Creation and Training"],"metadata":{"id":"nTOWw4sGLEF2"}},{"cell_type":"code","source":["input_shape = (224, 224, 3)\n","num_classes = 3\n","\n","input = tf.keras.Input(shape=input_shape)\n","x = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", name=\"first_conv\")(input)\n","x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n","x = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(x)\n","x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n","x = tf.keras.layers.Flatten()(x)\n","x = tf.keras.layers.Dropout(0.5)(x)\n","pred = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n","\n","model = tf.keras.Model(inputs=input, outputs=pred)"],"metadata":{"id":"jbTOGrNJKilK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(\n","    loss=tf.keras.losses.CategoricalCrossentropy(),\n","    optimizer=tf.keras.optimizers.RMSprop(),\n","    metrics=[\"accuracy\"],\n",")\n","\n","history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n","\n","test_scores = model.evaluate(test_ds, verbose=2)\n","print(\"Test loss:\", test_scores[0])\n","print(\"Test accuracy:\", test_scores[1])"],"metadata":{"id":"2QyxwQcBLRvA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"n6fcJaVQLWnU"},"execution_count":null,"outputs":[]}]}